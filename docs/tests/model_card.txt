# GLM-5 Model Card

## Overview

GLM-5 is a 745B parameter Mixture-of-Experts language model developed by Zhipu AI. Released under the MIT License. 48 expert layers with top-4 routing, yielding 180B active parameters per forward pass. Training corpus: 15T tokens across 96 languages.

## Benchmark Results

| Benchmark | Score |
|-----------|-------|
| MMLU | 87.3% |
| HumanEval | 82.1% |
| GSM8K | 94.6% |
| MATH | 71.8% |
| ARC-Challenge | 96.2% |
| HellaSwag | 95.8% |
| TruthfulQA | 68.4% |
| WinoGrande | 87.9% |

## Limitations

The model should not be used for medical diagnosis, legal advice, or financial trading without human oversight. Performance on low-resource languages (fewer than 100M training tokens) may degrade significantly. The model has not been evaluated for factual accuracy beyond the TruthfulQA benchmark. Known failure modes include: arithmetic errors above 8-digit numbers, inconsistent persona maintenance beyond 32K context, and citation hallucination in academic contexts.

## Hardware Requirements

Full precision (BF16) requires 1.5TB VRAM across 8x H100 GPUs. AWQ 4-bit quantization reduces requirement to 380GB (4x H100 or 8x A100). GGUF Q4_K_M format enables single-GPU inference on 48GB+ cards (RTX 6000 Ada, A6000) with degraded throughput. Maximum context length: 128,000 tokens. Recommended KV-cache: 32GB for full context utilization.

## Licensing

Released under the MIT License. Commercial use is permitted without restriction. Fine-tuning and distribution of derivative works are allowed. You must include the original copyright notice and license text in all copies or substantial portions of the software. The model name "GLM-5" is a trademark of Zhipu AI and may not be used to endorse derivative products without written permission.

## Safety

The model includes built-in safety training via RLHF and Constitutional AI methods. A separate safety classifier (GLM-Guard) is recommended for production deployments. The safety classifier shall be run on all user inputs and model outputs in production. Organizations deploying this model must implement logging sufficient to support incident investigation. The model shall not be used for mass surveillance, autonomous weapons systems, or social scoring applications.
